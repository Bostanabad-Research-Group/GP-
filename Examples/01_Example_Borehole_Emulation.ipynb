{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpplus.models import GP_Plus\n",
    "from gpplus.test_functions.analytical import borehole\n",
    "from gpplus.preprocessing import train_test_split_normalizeX\n",
    "from gpplus.utils import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation and prepration:\n",
    "The next step is to generate the data, standardize it and separate it to train-test sets. Here we generate 10500 data and use 5% of that for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1245)\n",
    "X, y = borehole(n=10000, random_state=12345)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split_normalizeX(X, y, test_size=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the GP+ model: Firstly, we create the model using GP_Plus command, and then the model is optimized with model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GP_Plus(Xtrain, ytrain, device='cuda')\n",
    "model.fit(n_jobs=-1, num_restarts=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the : After traning the model, we assess its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluation(Xtest, ytest)\n",
    "noise = model.likelihood.noise_covar.noise.detach() * model.y_std**2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
